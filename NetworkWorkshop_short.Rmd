---
title: A Brief Introduction to Archaeological Networks in R
author: "Matthew A. Peeples"
date: "March 26th, 2019"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
require(knitr)
# Set so that long lines in R will be wrapped:
opts_chunk$set(tidy.opts=list(width.cutoff=75),tidy=TRUE)
```

&nbsp;
&nbsp;
&nbsp;

# Citing this Document

This document can be cited as follows:

#### Peeples, Matthew A.
#### 2019  A Brief Introduction to Archaeological Networks in R. [online]. Available: http://www.mattpeeples.net/netintro.html

&nbsp;
&nbsp;
&nbsp;

# Getting Started

This markdown document provides code and detailed examples associated with a segment of an R Workshop held on March 26th, 2019 in Cambridge, UK at the "Big Data in Archaeology" conference hosted by the McDonald Instititue of Archaeological Research. This document assumes you have a basic knowledge of network science terminology and at least some basic familiarity with R and R Studio. If you are new to R, I recommend you first run through the brief Code School examples focused on R available here (http://tryr.codeschool.com/). The examples below can be run by simply copying and pasting the code below but modifications will require a bit of additional experience. For those new to network science in general, I recommend you start by reading the [Peeples 2019](http://em.rdcu.be/wf/click?upn=lMZy1lernSJ7apc5DgYM8eb588AVkkcBfKtFJwHweNU-3D_eLFMrKDT8iBxZ-2Fbnk-2BZqvY55CKUlNllxlT57rIWJS3TU-2F9tBicr0BXI3vG7L8zmwZ8NRJMh40gv9168aNLWY2e-2F2DgXrAo8J4yfwoT56zMO8axLjqySFJhxj4rrsTgLiJNOsASs267rNlI1IEEwXqv30MXgPc6eosYTCtraQTfhrmh-2BC1Hm4W9lESSyfAf3DCAquQwPV-2FUrAK9KOvX0pDQvhoFwNA8FYHodIPUV4qw9AYG8c-2B1PGlIUWPBmc4tSt1BitaHQGZqaH-2Fpc5Gt3K-2Bw-3D-3D) and Brughmans 2013 review articles (see recommended bibliography for more details). For those with more background in R and network statistics, there is also a more indepth version of this tutorial that goes into many more statistical techniques for evaluating network metrics and sensitivity analyses posted [here](http://www.mattpeeples.net/netstats.html)

&nbsp;
&nbsp;
&nbsp;

# Getting Our Data into R

For the purposes of this workshop we will be using a real archaeological dataset as an example pulled from the Digital Archaeological Record (tDAR). These data are derived from research previously conducted by me associated with my "Connected Communities" book with the University of Arizona Press (Peeples 2018). These data represent the results of an analysis which defined clusters of cooking pottery from the Zuni/Cibola region of Arizona and New Mexico (ca. AD 1150-1325) based on a series of technological attributes recorded for just over 2,200 individual vessels. In the workshop we'll practice searching for and retrieving these data directly from tDAR but I am also providing them here for future reference. This dataset is divided into two .csv files, the first with the counts of ceramic technological clusters by site and a second  with the locations of those sites (not on tDAR). To ensure the security of site locational information as required by the state data repositories charged with maintaining these data, I have randomly relocated each settlement between 7-10 kilometers from their actual locations. 

```{r, out.width = "600px", echo=F, fig.cap="Map of the Cibola region and the sites included in this analysis along with the frequencies of technological clusters by sub-region"}
knitr::include_graphics("http://www.mattpeeples.net/pics/Figure6.6.jpg")
```
&nbsp;

Right click and choose "save as" to download the [ceramic data](http://www.mattpeeples.net/ceramic_clust.csv) and [attribute data](http://www.mattpeeples.net/ceramic_clust_attr.csv).

The code below imports these data from the .csv files into objects we can use in R. Before running the code below, however, we need to ensure that our R session is set to the correct working directory (the location where you placed the .csv files for this workshop). To do that, go to the menu bar at the top and click Session > Set Working Directory > Choose Directory and navigate to the place on your hard drive where these files reside (alternatively you can hit Ctrl + Shift + H and then navigate to the appropriate directory). Once you have done that, you will be able to execute the code below by simply copying the text and then pasting it into the R console.

Let's start by importing our ceramic and attribute data.

```{r import-data}
# Import ceramic ceramic data into an object named ceramic. row.names=1 sets the first column values to the row names for each item.
ceramic <- read.csv(file='ceramic_clust.csv',row.names=1)
# Import attribute data into an object named ceramic.attr
ceramic.attr <- read.csv('ceramic_clust_attr.csv',row.names=1)
```

&nbsp;
&nbsp;
&nbsp;

# Installing and initializing the necessary libraries

For the purposes of this workshop, we will rely on a few pre-existing R packages. In order to use these packages in a new installation of R and R-studio, we first need to install them. Note that you will only need to do this once on each new installation of R/R-Studio. To install packages, you can click on the "Packages" tab in the window in the bottom right of R studio, then click the "Install" button at the top and type the names of the packages separated by commas. Alternatively you can install packages from the console by simply typing "install.packages('nameofpackagehere')" without the quotation marks. 

For the purposes of this workshop we will rely on several existing packages. Copy the line below into the console or follow the instructions to install using the packages tab:

install.packages('statnet','tnet','vegan','FastKNN','kableExtra','ggraph','GGally')

Once you have installed these packages we use the library console command to initialize our packages. 

```{r packages, message=F, warning=F}
library(statnet) #includes the libraries network, sna, and ergm
library(tnet) #includes the library igraph
library(vegan)
library(FastKNN)
library(kableExtra)
library(ggraph)
library(GGally)
```

&nbsp;
&nbsp;
&nbsp;

# Defining custom functions for our analyses

In addition to these R packages, there are also a few additional functions that we will need to define manually for several of our analyses below. Specifically, we want to be able to take our ceramic frequency data and convert that into a symmetric similarity or distance matrix that we will use to define and weight our networks. For the examples below, we will rely on four methods for defining these matrices: 1) Co-presence of types, 2) Brainerd-Robinson similarity, 3) $\chi^{2}$ distances, and 4) $k$ nearest neighbors based on the site locations. These are only a few among a wide variety of options. 

&nbsp;

#### Co-presence

The first simple measure we will use for defining networks here is the number of categories that are co-present at pairs of sites. We can calculate this measure through simple matrix algebra. First, we create a binary incidence matrix of ceramic counts by site by simply dichotomizing our count data (a matrix with 1 for all categories that are present and 0 elsewhere). We can define that incidence matrix as $A$ and the transpose (switching rows and columns) of that matrix as $A^{T}$ we can find the number of categories that overlap between sites $P$ as:
$$P=A * A^{T}$$

The result of this procedure is a symmetric matrix with the number of rows and columns determined by the number of nodes comparing each site to every other site with each cell represents counts of co-occurrence between pairs of sites. The diagonal of this matrix represents the total number of categories present for the site denoted by that row. In many cases, we may not want to count rare occurrences as "present" and may instead want to create a threshold absolute value or proportion that a given category must exceed to be counted as "present" for creating our matrix. In the example we will use here today a category must represent at least 25% of a row to be considered "present" in this calculation. The code below could be easily modified to use a different cutoff and the choice of cutoff is an important decision with substantive impacts on our networks. 

The chunk of code below defines a procedure for calculating simple co-presence for all categories representing more than 25% of a given row. We then create a new object called "ceramicP" which represents this matrix of co-occurrence from site to site.

```{r co-presence}
co.p <- function (x,thresh=0.25) {
  #create matrix of proportions from ceramic
  temp <- prop.table(as.matrix(x),1) 
  # define anything with greater than or equal to 0.1 as present (1) 
  temp[temp>=thresh] <- 1 
  # define all other cells as absent (0)
  temp[temp<1] <- 0 
  # matrix algebraic calculation to find co-occurence (%*% indicates matrix multiplication)
  out <- temp%*%t(temp) 
return(out)}

# run the function
ceramicP <- co.p(ceramic)

# display the results
kable(ceramicP) %>%
  kable_styling() %>%
  scroll_box(width = "100%", height = "300px")
```

&nbsp;

#### Brainerd-Robinson Similarity

The next metric we will use here is a rescaled version of the Brainerd-Robinson (BR) similarity metric. This BR measure is commonly used in archaeology including in a number of recent (and not so recent) network studies. This measure represents the total similarity in proportional representation of categories and is defined as:

$$S = {\frac{2-\sum_{k} \left|x_{k} - y_{k}\right|} {2}}$$

where, for all categories $k$, $x$ is the proportion of $k$ in the first assemblage and $y$ is the proportion of $k$ in the second. This provides a scale of similarity from 0-1 where 1 is perfect similarity and 0 indicates no similarity. For this example, we use the "vegdist" function from the "vegan" package which has this measure and many other distance metrics built in (Brainard-Robinson is referred to as Manhattan distance in this package). This chunk ends by running this function for our sample dataset defining a new object "ceramicBR" with the resulting similarity matrix.Note that by default, vegdist calculates this as a distance rather than a similarity. As the maximum possible distance is 2 we convert this to a similarity by subtracting the results from 2 and the rescale from 0 to 1 by dividing the result by 2. 

```{r Branard-Robinson}
ceramic.p <- prop.table(as.matrix(ceramic), margin = 1) # This line converts the ceramic cluster frequency table to a table of proportions by row

# The following line uses the vegdist function to calculate the Brainard-Robinson similarity score. 
ceramicBR <- (2-as.matrix(vegdist(ceramic.p, method='manhattan')))/2

# display the results
kable(ceramicBR) %>%
  kable_styling() %>%
  scroll_box(width = "100%", height = "300px")
```

&nbsp;

#### $\chi^{2}$ Distance

The next measure we will use is the $\chi^{2}$ distance metric which is the basis of correspondence analysis and related methods commonly used for frequency seriation in archaeology (note that this should probably really be called the $\chi$ distance since the typical form we use is not squared, but the name persists this way in the literature so that's what I use here). This measure is defined as:

$$\chi_{jk} = \sqrt{\sum \frac 1{c_{j}} 
({x_{j}-y_{j})^{2}}}$$

where $c_j$ denotes the $j_{th}$ element of the average row profile (the proportional abundance of $j$ across all rows) and $x$ and $y$ represent row profiles for the two sites under comparison. This metric therefore takes raw abundance (rather than simply proportional representation) into account when defining distance between sites. The definition of this metric is such that rare categories play a greater role in defining distances among sites than common categories (as in correspondence analysis). This measure has a minimum value of 0 and no theoretical upper limit. 

The code for calculating $\chi^{2}$ distances is defined in the chunk below and a new object called "ceramicX" is created using this measure. It is sometimes preferable to rescale this measure so that it is bounded between 0 and 1. We create a second object called "ceramicX01" which represents rescaled distances by simply dividing the matrix by the maximum observed value (there are many other ways to scale this measure but this simple option will be fine for our current purposes).

```{r Chi-squared Distance}
chi.dist <- function(x) {
  rowprof <- x/apply(x,1,sum) # calculates the profile for every row
  avgprof <- apply(x,2,sum)/sum(x) # calculates the average profile
  # creates a distance object of $\chi^{2}$ distances
  chid <- dist(as.matrix(rowprof)%*%diag(1/sqrt(avgprof))) 
  # return the reults
  return(as.matrix(chid))} 

# Run the script and then create the rescaled 0-1 version
ceramicX <- chi.dist(ceramic)
ceramicX01 <- ceramicX/max(ceramicX)

# display the results
kable(ceramicX01) %>%
  kable_styling() %>%
  scroll_box(width = "100%", height = "300px")
```

&nbsp;

#### $k$ Nearest Neighbors

The measures above all rely on the ceramic frequency data to calculate similarity/distance among pairs of sites. It is often the case that we want to define networks based on spatial distances and neighborhoods instead. This can be done in a wide variety of ways and I direct readers to the references at the end of this document for more information (Verhagen 2017). 

For the purposes of this workshop, we will use a very simple measure of spatial connectivity where we will define a network based on $k$ nearest neighbors. For example, if $k$ = 3 then each node will be connected to the 3 closest nodes in geogrpahic space. In the example here we will use $k$ = 5. 

Note that unlike our other measures this measure is not symmetric. This means that site 1 may be among site 2's $k$ closest neighbors even if site 2 is not among site 1's $k$ closest neighbors. 

```{r K nearest neighbors}
# Create a distance matrix using Euclidean distances based on the site coordinates in ceramic.attr
distMatrix <- as.matrix(dist(ceramic.attr))

# set k as 5 and create a function that calculates the 5 nearest neighbors for each node
k <- 5
nrst <- lapply(1:nrow(distMatrix), function(i) k.nearest.neighbors(i, distMatrix, k = k))

# the chunk of code below creates a symmetric matrix of 0s and then fills cells with 1 where two sites are k nearest neighbors
dist.knn <- matrix(nrow = dim(distMatrix), ncol=dim(distMatrix),0) 
for(i in 1:length(nrst)) for(j in nrst[[i]]) dist.knn[i,j] = 1

# set row and column names
row.names(dist.knn) <- row.names(ceramic.attr)
colnames(dist.knn) <- row.names(ceramic.attr)

# display the results
kable(dist.knn) %>%
  kable_styling() %>%
  scroll_box(width = "100%", height = "300px")
```

&nbsp;
&nbsp;
&nbsp;

# Creating and plotting network objects from our similarity/distance matrices

Now that we have defined our four measures of similarity or distance, the next step is to convert these into network objects that our R packages will be able to work with. We can do this by either creating binary networks (where ties are either present or absent) or weighted networks (which in many cases are simply the raw similarity/distance matrices we calculated above). I will provide examples of both approaches, starting with simple binary networks. There are many ways to define networks from matrices like those we generated above and my examples below should not been seen as an exhaustive set of approaches.

&nbsp;

#### Creating binary network objects

First, we will create binary networks using our ceramic ware co-occurrence matrix. Sites that share a single co-occurrence will be defined as connected here. We then use the "network" function to create a network object using the argument "directed=F" to let the function know that our data are from a symmetric matrix and that ties always extend in both directions between pairs of linked nodes. See help(network) for more details on options here. 

After we create this new network object we plot it first using the default graph layout (Fruchterman-Reingold - We'll discuss what this is in the workshop) and then based on the geographic location of our nodes. We're not going to spend a lot of time exploring network plotting procedures in this workshop, but for those of you who may be interested in making far prettier graphs than those used here for demonstration purposes, I would recommend exploring the new "ggraph" package. (https://github.com/thomasp85/ggraph)

```{r }
# create network object from co-occurrence
Pnet <- network(ceramicP,directed=F)
# Now let's add names for our nodes based on the row names of our original matrix
Pnet %v% 'vertex.names' <- row.names(ceramicP)
# look at the results
Pnet 

# set up for plotting two plots, side by side by setting the pot to 1 row, 2 columns
par(mfrow=c(1,2)) 
# plot network using default layout
plot(Pnet, edge.col='gray', edge.lwd=0.25, vertex.cex=0.5,main='co-presence network')
# plot network using geographic coordinates
plot(Pnet, edge.col='gray', edge.lwd=0.25, vertex.cex=0.5, coord=ceramic.attr)
par(mfrow=c(1,1)) # return to single plotting mode
```

The next chunk of code will produce a network based on our BR similarity matrix. In this example, we define ties as present between pairs of sites when they share more than 65% commonality (BR > 0.65) in terms of the proportions of ceramic wares recovered from both sites in a dyad. This threshold was selected based on an analysis not described here but discussed in detail in Chapter 5 of Peeples 2018.

In the code below, the event2dichot function (from the statnet/network package) takes our matrix and divides it into 1s and 0s based on the cut off we choose. Here we're using and 'absolute' cut off meaning we're assigning a specific value to use as the cut off (0.65) and defining all similarity values higher than that cutoff as 1 and all other dyads as 0. We then send the output of this function to the network function just as before. After examining our new network we then plot it both using a graph layout and geographic locations.

```{r fig.height=6,fig.width=10}
# Define our binary network object from BR similarity
BRnet <- network(event2dichot(ceramicBR,method='absolute',thresh=0.65),directed=F)
# Now let's add names for our nodes based on the row names of our original matrix
BRnet %v% 'vertex.names' <- row.names(ceramicBR)
# look at the results.
BRnet

par(mfrow=c(1,2)) # set up for plotting two plots, side by side
# plot network using default layout
plot(BRnet, edge.col='gray', edge.lwd=0.25, vertex.cex=0.5,main='BR network')
# plot network using geographic coordinates
plot(BRnet, edge.col='gray', edge.lwd=0.25, vertex.cex=0.5, coord=ceramic.attr)
par(mfrow=c(1,1)) # return to single plotting mode
```

In the next chunk of code we will use the $\chi^2$ distances to create binary networks. This time, we will not use an absolute value to define ties as present, but instead will define those similarities (1-distances) greater than 80 percent of all similarities as present. We will then once again plot just as above.

```{r fig.height=6,fig.width=10}
# Note we use 1 minus ceramicX01 here so to convert a distance to a similarity
Xnet <- network(event2dichot(1-ceramicX01,method='quantile',thresh=0.80),directed=F)
# Once again add vertex names
Xnet %v% 'vertex.names' <- row.names(ceramicX01)
# look at the results
Xnet

par(mfrow=c(1,2)) # set up for plotting two plots, side by side
# plot network using default layout
plot(Xnet, edge.col='gray', edge.lwd=0.25, vertex.cex=0.5,main='Chi-squared network')
# plot network using geographic coordinates
plot(Xnet, edge.col='gray', edge.lwd=0.25, vertex.cex=0.5, coord=ceramic.attr)
par(mfrow=c(1,1)) # return to single plotting mode
```

Finally, we now plot the network based on the $k$ nearest neighbors spatial definition described above. As mentioned previously, the $k$ nearest neighbors procedure can produce directed ties as when A is a NN of B, B may not be a NN of A. Thus, we use the "directed=T" argument in the network call below. This also means that we can use arrows to indicate the direction of each tie in the plot.

```{r fig.height=6,fig.width=10}
# Create network object with directed ties
dist.net <- network(dist.knn,directed=T)
# Once again add vertex names
dist.net %v% 'vertex.names' <- row.names(ceramic.attr)
# look at the results
dist.net

par(mfrow=c(1,2)) # set up for plotting two plots, side by side
# plot network using default layout
plot(dist.net, edge.col='gray', edge.lwd=0.25, vertex.cex=0.5,main='K nearest neighbors network, k=5')
# plot network using geographic coordinates
plot(dist.net, edge.col='gray', edge.lwd=0.25, vertex.cex=0.5, coord=ceramic.attr)
par(mfrow=c(1,1)) # return to single plotting mode
```

&nbsp;

#### Creating and plotting weighted network objects

It is also possible to use R to create weighted networks where individual edges are valued. I have found that this works reasonably well with networks of co-presence or something similar (counts of mentions in texts or monuments for example) but this does not perform well when applied to similarity or distance matrices (because every possible link has a value, however small, so the network gets unwieldy very fast). In the latter case, I have found it is better to just work directly with the underlying similarity/distance matrix or to provide a cut-off below which ties are not shown.

Creating a weighted network object in R is easy and only requires a slight modification from the procedure above. In the chunk of code below, I will simply add the arguments "ignore.eval=F" and "names.eval='weight'" to let the network function know we would like weights to be retained and we would like that attribute called 'weight'. We will apply this to the matrix of co-presence defined above and then plot the result showing the weights of individual ties. Although it is difficult to tell with a network this size, the lines defining the edges are scaled based on their edge weights. Although we only show this approach for the co-presence network, these same arguments work with the other matrices defined above. In this case, all ties have a weight of 1 or 2 with ties with a weight of 2 shown in red.

```{r fig.height=6,fig.width=10}
# create weighted network object from co-occurrence matrix by adding the ignore.eval=F argument
Pnet2 <- network(ceramicP,directed=F,ignore.eval=F,names.eval='weight')
Pnet2 %v% 'vertex.names' <- row.names(ceramicP)
Pnet2

par(mfrow=c(1,2)) # set up for plotting two plots, side by side
# plot weighted network using default layout
plot(Pnet2, edge.col='weight', edge.lwd='weight', vertex.cex=0.5, vertex.col='red',
     main='co-presence weighted network')
# plot weighted network using geographic coordinates
plot(Pnet2, edge.col='weight', edge.lwd='weight', vertex.cex=0.5, coord=ceramic.attr, vertex.col='red')
par(mfrow=c(1,1)) # return to single plotting mode
```

If we wished to do this for a similarity network, there may be a few additional steps to consider. In this example, using the cutoff defined above, we can eliminate the weights below the threshold of 0.65 so that those will not be shown. There are many more plotting options within R base graphics and ggplot/ggraph and I direct you to the help documents for those packages for more details as well as the additional examples below.

```{r}
ceramicBR2 <- ceramicBR # create object to convert into weighted network object
ceramicBR2[ceramicBR2<0.65] <- 0 # set values for similarities less than 0.65 to 0 sot that they are not shown
BRnet2 <- network(ceramicBR2,directed=F,ignore.eval=F,names.eval='weight') # create weighted network object
BRnet2 %v% 'vertex.names' <- row.names(ceramicP)
BRnet2 

par(mfrow=c(1,2)) # set up for plotting two plots, side by side
edge.set <- round(get.edge.value(BRnet2,'weight')*100,0)-64 #extract edge values and round, subtract 64 so that the minimum value will be 1. This procedure would need to be modified if a different cutoff were used.
edge.cols <- colorRampPalette(c('gray','darkblue'))(max(edge.set)) #create color pallette for the number of values represented
plot(BRnet2,edge.col=edge.cols[edge.set],edge.lwd='weight',vertex.cex=0.5,vertex.col='red',main='co-presence weighted network') # plot weighted network using default layout
plot(BRnet2,edge.col=edge.cols[edge.set],edge.lwd='weight',vertex.cex=0.5,coord=ceramic.attr,vertex.col='red',main='co-presence weighted network') # plot weighted network using geographic coordinates
par(mfrow=c(1,1)) # return to single plotting mode
```

&nbsp;
&nbsp;
&nbsp;

# Calculating graph-level and node-level metrics

One of the most common kinds of analysis for archaeological and other networks is the calculation of measures of node/edge centrality and graph centralization. There are many different measures in the literature each appropriate for different kinds of research questions and data formats (see Borgatti and Everett 2006). I will not cover the interpretation of these network metrics in depth in this workshop, but we will be using several common measures as our means of assessing the impact of missing data and other kinds of uncertainty on our interpretations of archaeological networks. 

In this section, I briefly describe the network metrics we will use and then define a function to easily calculate multiple measures simultaneously on multiple networks. The primary measures we will use are the binary and weighted versions of: 1) degree centrality, 2) betweenness centrality, and 3) eigenvector centrality. I direct readers to Peeples and Roberts (2013) and especially the online supplemental materials for that article for more details on the calculation of these metrics.

Degree centrality for a node is defined as the total number of direct connections in which that node is involved. In weighted networks, this is simply the total weight of all connections for that node (minus 1 to remove self-loops). Betweenness centrality is defined as the number of shortest paths between pairs of nodes in a network involving the target node divided by the total number of shortest paths in the network as a whole. For binary networks, shortest paths are defined as the smallest number of direct ties that must be crossed to get from one specific node to another. Calculating betweenness centrality for weighted networks is a bit more complicated. The method we use here come from Opsahl and others (2010). This approach defines shortest paths as the "path of least resistance" between pairs of target nodes. In other words, the stronger the path (the higher the edge weights) the "shorter" it is according to this algorithm. Refer to Peeples and Roberts (2013) for more details. Eigenvector centrality is a measure of a node's importance in a network defined in relation to the first eigenvector of the adjacency matrix of nodes for both binary and weighted networks. For both binary and weighted networks, a node's eigenvector centrality score is proportional to the summed scores of other nodes to which it is connected. In other words, eigenvector centrality for a node will increase if a node is either connected to lots of other nodes, or if a node is connected to highly central nodes. We rescale this measure as is commonly seen in the network science literature so that the sum of squared scores is equal to the total number of nodes in that network.

Calculating individual centrality measures usually involves just one or two lines of code as the examples below illustrate.

```{r}
## degree centrality
dg <- as.matrix(sna::degree(BRnet,gmode='graph'))
## eigenvector centrality
eg <- as.matrix(sna::evcent(BRnet)) 
eg <- sqrt((eg^2)*length(eg)) # standardized to start network as is frequently seen in the literature
## betweenness centrality
bw <- sna::betweenness(BRnet,gmode='graph') 

# calculate weighted degree as the sum of weights - 1
dg.wt <- as.matrix(rowSums(ceramicBR)-1) 
# calculate weighted eigenvector centrality and rescale
eg.wt <- as.matrix(sna::evcent(ceramicBR)) 
eg.wt <- sqrt((eg.wt^2)*length(eg.wt)) # standardize to start network
# calculate weighted betweenness from the tnet package (we use the suppressWarnings package to avoid notifications)
bw.wt <- suppressWarnings(betweenness_w(ceramicBR,directed=F))[,2] 

head(dg)
```

To simplify the rest of the discussion, I have created a function that calculates multiple centrality measures at the same time. The chunk of code below contains two functions: 1) the first calculates the three measures of centrality described above for binary networks and 2) the second calculates these measures for weighted networks (or similarity matrices). The results are by default returned in a matrix with a column for each measure and a row for each node. Note that the statnet/sna package uses some of the same names for functions as tnet/igraph. Thus, we must specify which package we mean to use in the code below (e.g., sna::degree means the degree calculation method used in the sna package which is initialized through statnet. If we wished to use the igraph version we would instead use igraph::degree).

```{r}
# Calculate centrality scores for binary networks
net.stats <- function(y){ 
# calculate degree centrality
dg <- as.matrix(sna::degree(y,gmode='graph')) 
# calculate and scale eigenvector centrality
eg <- as.matrix(sna::evcent(y)) 
eg <- sqrt((eg^2)*length(eg)) 
# calculate betweenness centrality
bw <- sna::betweenness(y,gmode='graph') 
# combine centrality scores into matrix
output <- cbind(dg,eg,bw) 
rownames(output) <- rownames(as.matrix(y)) 
colnames(output) <- c('dg','eg','bw') 
return (output)} # return results of this function

# Calculate centrality scores for weighted networks (similarity matrices)
net.stats.wt <- function(y){ 
# calculate weighted degree as the sum of weights - 1
dg.wt <- as.matrix(rowSums(y)-1) 
# calculate weighted eigenvector centrality and rescale
eg.wt <- as.matrix(sna::evcent(y)) 
eg.wt <- sqrt((eg.wt^2)*length(eg.wt))
# calculate weighted betweenness from the tnet package (we use the suppressWarnings package to avoid notifications)
bw.wt <- suppressWarnings(betweenness_w(y,directed=F))[,2] 
output <- cbind(dg.wt,eg.wt,bw.wt) 
rownames(output) <- rownames(as.matrix(y))
colnames(output) <- c('dg.wt','eg.wt','bw.wt') 
return (output)} # return results of this function
```

Now let's calculate these measures for our networks defined above and look at the first couple of rows for the final example based on the $k$ nearest neighbors network.

```{r}
# net stats for binary co-presence network
co.p.stats <- net.stats(Pnet)
# net stats for binary BR similarity network
BR.stats <- net.stats(BRnet)
# net stats for binary X^2 similarity network (1-distance)
X.stats <- net.stats(Xnet)
# net stats for KNN network
dist.stats <- net.stats(dist.net)
head(dist.stats)
```

And now let's calculate the weighted versions. Note that we don't include the KNN network here as there are no weights to those ties.

```{r warning=F}
# net stats for weighted co-presence network
co.pw.stats <- net.stats.wt(ceramicP)
# net stats for weighted BR similarity network
BR.stats.w <- net.stats.wt(ceramicBR)
# net stats for X^2 similarity (1-distance)
X.stats.w <- net.stats.wt(1-ceramicX01)
head(X.stats.w)
```

It is also often informative to evaluate graph-level measures of centralization. In the code below, we calculate centralization measures associated with the node-level centrality measures described above. These measures are essentially a measure of how central all nodes in our network are in relation to a theoretical maximum. We can calculate most measures using existing functions but we need to create a custom function for calculating weighted betweenness centralization. Again Peeples and Roberts (2013) provide more details. 

```{r}
## calculate centralization measures for binary network 
cent.bin <- function(net) {
output <- matrix(0,1,3)
colnames(output) <- c('degree','between','eigen')
#calculate binary degree centralization
output[1,1] <- centralization(net,sna::degree,normalize=T) 
#calculate binary eigenvector centralization
output[1,2] <- centralization(net,sna::evcent,normalize=T) 
#calculate binary betweenness centralization
output[1,3] <- centralization(net,sna::betweenness,normalize=T) 
return(output)}

# define function for calculating weighted betweenness centralization
bw.cent <- function(x){ 
Cstar <- max(x) 
Csum <- (Cstar-x) 
num <- 2*(sum(Csum)) 
den <- ((length(x)-1)^2)*(length(x)-2) 
out <- num/den 
return(out)} # output result of this function

## calculate centralization measures for weighted network 
cent.wt <- function(sim) {
output <- matrix(0,1,3)
colnames(output) <- c('degree.wt','eigen.wt','between.wt')
#calculate degree centralization
output[1,1] <- centralization(sim,sna::degree,normalize=T) 
#calculate eigenvector centralization
output[1,2] <- centralization(sim,sna::evcent,normalize=T) 
# calculate betweenness centralization
output[1,3] <- bw.cent(sim)
return(output)}
```

Now let's see examples of a couple of results using these functions focusing on the BR measure for now. 

```{r}
# BR binary net centralization
cent.bin(BRnet)
# BR similarity centralization
cent.wt(ceramicBR)
```

&nbsp;
&nbsp;
&nbsp;

# Visualizing Network Metrics

Another procedure that is often useful for exploratory analysis of archaeological networks is to visualize networks using attributes or network metrics to scale or weight the sizes of nodes or edges. There are way more options than I could ever hope to show here but I can highlight a few of the most common plotting formats and options here.

The first set of examples focuses on the "plot.network"" function within the SNA package. Note that "vertex.cex" is being used here to set the size of nodes based on degree centrality. Becuase the values of degree vary widely, I divide the value by 6 to keep the points to a reasonable size. You can experiment with similar scaling techniques and I'll discuss more of these in the workshop.

```{r}
par(mfrow=c(1,2)) # set up for plotting two plots, side by side
# plot network using default layout
plot(BRnet,displaylabels=T,label.cex=0.5,vertex.cex=sna::degree(BRnet)/6, edge.lwd=0.25, edge.col='gray')
# plot network using geographic coordinates
plot(BRnet,displaylabels=T,label.cex=0.5,vertex.cex=sna::degree(BRnet)/6, coord=ceramic.attr, edge.lwd=0.25, edge.col='gray')
par(mfrow=c(1,1)) # return to single plotting mode
```

The next set of examples shows some of the advanced plotting options that are available through the ggraph and tidygraph packages. These packages provide many more options for color, edge weights, and even animation. I encourage you to experiment by modifying the code below and looking in the help(ggraph) documents online as well as many excellent tutorials you can find on the internet. 

```{r warning=F, message=F}
BRnet %>% 
  ggraph(layout = 'fr') + 
  geom_edge_link(color='gray') + 
  geom_node_point(aes(size = bw, color = bw)) + 
  scale_color_continuous(guide = 'legend') + 
  theme_graph()

BRnet %>% 
  ggraph(layout = 'manual',  node.positions = ceramic.attr[,1:2]) + 
  geom_edge_link(color='gray') + 
  geom_node_point(aes(size = bw, color = bw)) + 
  scale_color_continuous(guide = 'legend') + 
  theme_graph()

edge_weight <- get.edge.value(BRnet2,'weight')
BRnet2 %>% 
  ggraph(layout = 'fr') + 
  geom_edge_link(aes(alpha=edge_weight), color='black') + 
  geom_node_point(aes(size = bw, color = bw)) + 
  geom_node_text(aes(label = name), repel=T)+
  scale_color_continuous(guide = 'legend') + 
  theme_graph()
```

&nbsp;
&nbsp;
&nbsp;

# Future directions

This document is by no means an exhaustive account of what R has to offer for archaeological networks. There are many more pre-built tools to experiment with and endless options for creating your own methods. I hope this inspires you to do more. If you've completed this tutorial and want to know more about network metrics and sensitivity, you can also try [this more advanced tutorial](http://www.mattpeeples.net/netstats.html) that was part of a full-day course at the Computer Applications in Archaeology meeting in 2017.

&nbsp;
&nbsp;
&nbsp;

# References Cited

Borgatti, Stephen P., and Martin G. Everett
 2006	A Graph-Theoretic Perspective on Centrality. *Social Networks* 28(4): 466-484.

Brughmans, Tom
 2013	Thinking Through Networks: A Review of Formal Network Methods in Archaeology. *Journal of Archaeological Method and Theory* 20: 623-662.
 
Brughmans, Tom and Matthew A. Peeples
 2017 [Trends in Archaeological Network Research: A Bibliometric Analysis](https://doi.org/10.25517/jhnr.v1i1.10). *Journal of Historical Network Research* 1(1):article 1.

Opsahl, Tore, Filip Agneessens, and John Skvoretz
 2010	Node Centrality in Weighted Networks: Generalizing Degree and Shortest Paths. *Social Networks* 32(3): 245-251.

Peeples, Matthew A., and John M. Roberts
 2013	To Binarize or Not to Binarize: Relational Data and the Construction of Archaeological Networks. *Journal of Archaeological Science* 40(7): 3001-3010.
 
Peeples, Matthew A.
 2018 *Connceted Communities: Networks, Identity, and Social Change in the Ancient Cibola World*. University of Arizona Press, Tucson, AZ.
 
Peeples, Matthew A.
 2019 [Finding a Place for Networks in Archaeology](http://em.rdcu.be/wf/click?upn=lMZy1lernSJ7apc5DgYM8eb588AVkkcBfKtFJwHweNU-3D_eLFMrKDT8iBxZ-2Fbnk-2BZqvY55CKUlNllxlT57rIWJS3TU-2F9tBicr0BXI3vG7L8zmwZ8NRJMh40gv9168aNLWY2e-2F2DgXrAo8J4yfwoT56zMO8axLjqySFJhxj4rrsTgLiJNOsASs267rNlI1IEEwXqv30MXgPc6eosYTCtraQTfhrmh-2BC1Hm4W9lESSyfAf3DCAquQwPV-2FUrAK9KOvX0pDQvhoFwNA8FYHodIPUV4qw9AYG8c-2B1PGlIUWPBmc4tSt1BitaHQGZqaH-2Fpc5Gt3K-2Bw-3D-3D). *Journal of Archaeological Research* (online first):1-49.
 
&nbsp;
&nbsp;

#### Additional Resources

In addition to the resource listed above Tom Brughmans and I (Brughmans and Peeples 2017) have compiled a large Zotero library of archaeological network literature that is freely available through the Historical Network Research organization [here](http://historicalnetworkresearch.org/bibliography/).

&nbsp;
&nbsp;
&nbsp;
